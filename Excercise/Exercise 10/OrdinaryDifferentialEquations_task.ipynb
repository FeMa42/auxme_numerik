{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerically solving Ordinary Differential Equations (ODEs)\n",
    "\n",
    "In this exercise we will look at how to solve ordinary differential equations (ODEs) numerically. We will use the Euler method, look at the stability of solving ODEs numerically and at higher order methods to solve ODEs like the Runge-Kutta method. This exerxise is based on the follwing sources: https://kyleniemeyer.github.io/ME373-book/content/intro.html \n",
    "\n",
    "This is only a short introduction to ODEs and how to solve the using numerical methods. If you want to learn more about ODEs, you can take a look here: http://faculty.washington.edu/sbrunton/me564/ \n",
    "This is a complete lecture with accompanying youtube videos (https://www.youtube.com/playlist?list=PLMrJAkhIeNNTYaOnVI3QpH7jgULnAmvPA) on ODEs and numerical methods to solve them.\n",
    "\n",
    "# Short introduction to Ordinary Differential Equations (ODEs)\n",
    "\n",
    "Ordinary Differential Equations (ODEs) are a fundamental concept in mathematics and engineering, used to model systems that change over time. An ODE is an equation that contains a function of one independent variable and its derivatives. The term \"ordinary\" is used in contrast with the term \"partial differential equation,\" which may be with respect to more than one independent variable.\n",
    "\n",
    "A first-order ODE can be written in the form:\n",
    "\n",
    "$$\n",
    "\\dot{x}=\\frac{dx}{dt} = f(t, x), \\hspace{1cm} x(t_0)=x_0\n",
    "$$\n",
    "\n",
    "where $x$ is the dependent variable, $t$ is the independent variable, and $f(t, x)$ is a function that describes the rate of change of $x$ with respect to $t$. The solution to this equation is a function $x(t)$ that satisfies the equation. \n",
    "\n",
    "A second-order ODE can be written in the form:\n",
    "\n",
    "$$\n",
    "\\frac{d^2x}{dt^2} = f\\left(t, x, \\frac{dx}{dt}\\right)\n",
    "$$\n",
    "\n",
    "where the function $f$ now also depends on the first derivative of $x$.\n",
    "\n",
    "Solving an ODE involves finding a function that satisfies the given equation. This can be done analytically for simple ODEs, but for more complex ODEs, numerical methods such as the Euler method, Runge-Kutta methods, or others can be used.\n",
    "\n",
    "When we look at the general form of a first-order ordinary differential equation (ODE) together with an initial condition, we have:\n",
    "\n",
    "$$\n",
    "\\dot{x}=f(x,t), \\hspace{1cm} x(t_0)=x_0\n",
    "$$\n",
    "\n",
    "We will look how we can solve it numerically and approximate the solution at discrete points in time using the Euler method. First let's think about how we could solve such an equation. We could integrate the equation from $t_0$ to $t_1$ to get a solution for $x(t_1)$. So let's look at how we can integrate an equation.\n",
    "\n",
    "## Numerical integration: Trapezoidal rule\n",
    "\n",
    "When we integrate the equationfrom above, we get:\n",
    "\n",
    "$$ \n",
    "x(b) = \\int_{a}^{b} f(x(t),t) dt, x(0) = x_0\n",
    "$$\n",
    "\n",
    "where $a$ and $b$ are the start and end points of the integration.\n",
    "\n",
    "You probably remember that you can solve a definite integrals ($ \\int_a^b f(x) dx $) intgral using the **trapezoidal rule**, which finds the area under the curve by creating trapezoids and summing their areas:\n",
    "$$ \n",
    "\\text{area under curve} = \\sum \\left( \\frac{f(x_{i+1}) + f(x_i)}{2} \\right) \\Delta x\n",
    "$$ \n",
    "\n",
    "where $\\Delta x$ is the width of the trapezoid.\n",
    "\n",
    "## Numrically Solving ODEs using Euler's Method\n",
    "\n",
    "When we need to solve ODEs of the form\n",
    "$$\n",
    "\\dot{x}=f(x,t), \\hspace{1cm} x(t_0)=x_0\n",
    "$$\n",
    "we need other methods to integrate the equation. All of them will work by starting at the initial conditions, and then using information provided by the ODE to march forward in the solution, based on an increment (i.e., step size) $\\Delta x$.  \n",
    "\n",
    "Let's look at a simple example first:\n",
    "\n",
    "$$\n",
    "\\frac{dx}{dt} = 4 t - \\frac{2 x}{t} , \\hspace{1cm} \\quad x(1) = 1\n",
    "$$\n",
    "\n",
    "For this problem we can find the general and particular solutions to compare our numerical results against:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{general: } x(t) &= t^2 + \\frac{t}{t^2} \\\\\n",
    "\\text{particular: } x(t) &= t^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Forward Euler Method:** Recall that the derivative, $\\dot{x}$, is the same as the slope or the tangent line to the curve $x(t)$. So, if we know the value of $x$ at a point, we can approximate the value of $x$ at a later point by drawing a line with slope $\\dot{x}$ and using the equation for a line to find the value of $x$ at the later point. At the starting point, $(x,t) = (1,1)$, where $\\dot{x} = 2$, this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "t_vals = range(1, 3, length=50)\n",
    "x_vals = t_vals.^2\n",
    "\n",
    "plot(t_vals, x_vals, label=\"Solution\")\n",
    "plot!([1, 2], [1, 3], linestyle=:dash, label=\"Slope at start\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to solve the following integral: \n",
    "\n",
    "$$ \n",
    "x(b) = \\int_{a}^{b} f(x(t),t) dt , \\hspace{1cm} x(t_0) = x_0.\n",
    "$$\n",
    "\n",
    "Let's consider the initial condition — the starting point — as $(t_i, x_i)$, and the next point in our numerical solution is $(t_{i+1}, x_{i+1})$, where $i$ represents an index over the interval $[1,N]$. Our step size is then $\\Delta t = t_{i+1} - t_i$.\n",
    "\n",
    "Based on our (simple) approximation to the first derivative based on slope, we can relate the derivative to our two points:\n",
    "$$\n",
    "\\left(\\frac{dx}{dt}\\right)_{i} = \\frac{x_{i+1} - x_i}{t_{i+1} - t_i} = \\frac{x_{i+1} - x_i}{\\Delta t}\n",
    "$$\n",
    "\n",
    "Then, solve this for our unknown:\n",
    "$$\n",
    "x_{i+1} = x_i + \\left(\\frac{dx}{dt}\\right)_i \\Delta t\n",
    "$$\n",
    "This is the **Forward Euler method**. \n",
    "\n",
    "We can also rewrite this if we assume that $x$ is a function of $t$ and $f(x,t)$ is defined as the derivative of $x$ with respect to $t$:\n",
    "$$\n",
    "x(t_{i+1}) = x(t_i) + f(x(t_i),t_i) \\Delta t\n",
    "$$\n",
    "    \n",
    "where $\\Delta t$ is the step size and $f(x(t_n),t_n)$ is the derivative of $x$ at $t_n$. \n",
    "\n",
    "We can use this to solve our equation numerically using a given step size $\\Delta x$ and march forward for a given number of steps $N$. For our example this will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_exact = range(1, 3, length=50)\n",
    "x_exact = t_exact .^ 2\n",
    "\n",
    "# our derivative function, dy/dx\n",
    "function dydx(t, x)\n",
    "    return 4 * t - (2 * x) / t\n",
    "end\n",
    "\n",
    "dt = 0.5\n",
    "t_vals = 1:dt:3\n",
    "x_vals = zeros(length(t_vals))\n",
    "\n",
    "# set initial condition\n",
    "x_vals[1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Implement the Loop for the Forward Euler Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over t_vals, calculating x_vals\n",
    "for idx in 1:length(t_vals)-1\n",
    "    \n",
    "    x_vals[idx+1] = ...\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t_exact, x_exact, label=\"Exact solution\")\n",
    "plot!(t_vals, x_vals, marker=:circle, markersize=5, linestyle=:dash, label=\"Numerical solution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Another way to obtain the recursion formula for the Forward Euler method is to use a Taylor series expansion. Recall that for well-behaved functions, the Taylor series expansion says\n",
    "$$\n",
    "x(t + \\Delta t) = x(t) + \\Delta t x^{\\prime}(t) + \\frac{1}{2} \\Delta t^2 x^{\\prime\\prime}(t) + \\frac{1}{3!} \\Delta t^3 x^{\\prime\\prime\\prime}(t) \\dots \\;.\n",
    "$$\n",
    "When we apply this formula to our (unknown) solution $x_i$ and cut off the terms of order $\\Delta t^2$ and higher; the derivative $\\dot{x}$ is given by our original ODE. We can see that this gives us the same recursion formula as above. We can also see that we are introducing some error on the order of $\\Delta t^2$ at each step. This is the *local truncation error*. The *global error* is the accumulation of error over all the steps, and is on the order of $\\Delta t$. Thus, the Forward Euler method is a **first-order** method, because its global error is on the order of the step size to the first power: error $\\sim \\mathcal{O}(\\Delta t)$.\n",
    "\n",
    "**Summary** Applying the Forward Euler method requires:\n",
    "\n",
    "1. Have a given first-order ODE: $\\frac{dx}{dt} = \\dot{x} = f(t,x)$. Complex and/or nonlinear problems are fine!\n",
    "2. Specify the step size $\\Delta t$.\n",
    "3. Specify the domain over which to integrate: $t_1 \\leq t \\leq t_n$\n",
    "4. Specify the initial condition: $x(t=t_1) = x_1$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability and Stiffness\n",
    "\n",
    "You have probably heared about **stability**, it has likely been regarding the stability of a *system*. Stable systems are those with well-behaved exact solutions, meaning they do not grow unbounded.\n",
    "In engineering we mostly focus (or want!) stable systems, although there are some interesting unstable systems such as those involving resonance, nonlinear dynamics, or chaos—generally we want to know when that happens so we can prevent it.\n",
    "\n",
    "We can also define the stability of a *numerical scheme*, which is when the numerical solution exhibits unphysical behavior. In other words, it blows up.\n",
    "\n",
    "For example, let's consider the relatively simple 1st-order ODE\n",
    "$$\n",
    "\\frac{dy}{dt} = -3 y\n",
    "$$\n",
    "with the initial condition $y(0) = 1$. As we will see, this ODE can cause explicit numerical schemes to become unstable, and thus it is a **stiff** ODE. (Note that we can easily obtain the exact solution for this problem, which is $y(t) = e^{-3 t}$.)\n",
    "\n",
    "Let's try solving this with the Forward Euler method, integrating over $0 \\leq t \\leq 20$, for a range of time-step size values: $\\Delta t = 0.1, 0.25, 0.5, 0.75$. \n",
    "\n",
    "### Task: Implement a general Forward Euler solver and plot the results for the different step sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dydt to integrate\n",
    "f(t, y) = -3 * y\n",
    "\n",
    "# we'll create a simple function to do forward Euler\n",
    "function forward_euler(t_end, y0, dt, f)\n",
    "    # Simple function to perform Forward Euler iteration\n",
    "    time = 0:dt:t_end\n",
    "    y = ...\n",
    "    y[1] = ..\n",
    "    for idx in 1:length(time)-1\n",
    "        y[idx+1] = ...\n",
    "    end\n",
    "    return time, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial condition\n",
    "y0 = 1\n",
    "t_end = 20\n",
    "\n",
    "dt = 0.1\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p1 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.25\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p2 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.5\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p3 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.75\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p4 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "plot(p1, p2, p3, p4, layout=(2, 2), legend=false)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the smaller step sizes, $\\Delta t = 0.1$ and $\\Delta t = 0.25$, we see that the solution is well-behaved. But, when we increase $\\Delta t$ to 0.5, we see some instability that goes away with time. Then, when we increase $\\Delta t$ to 0.75, the solution eventually blows up, leading to error **much** larger than what we should expect based on the method's order of accuracy (first) and the step size value.\n",
    "\n",
    "Compare this behavior to that for the ODE\n",
    "$$\n",
    "\\frac{dy}{dt} = e^{-t}\n",
    "$$\n",
    "which is **non-stiff**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dydt to integrate\n",
    "f(t, y) = exp(-t)\n",
    "\n",
    "# initial condition\n",
    "y0 = 1\n",
    "t_end = 10\n",
    "\n",
    "dt = 0.1\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p1 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.25\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p2 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.5\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p3 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.75\n",
    "time, y = forward_euler(t_end, y0, dt, f)\n",
    "p4 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "plot(p1, p2, p3, p4, layout=(2, 2), legend=false)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that the solution remains well-behaved even for larger time-step sizes, and the error matches the expected order based on the method and step-size value.\n",
    "\n",
    "In general numerical schemes can be:\n",
    "\n",
    "- **unstable**: the scheme blows up for any choice of parameters\n",
    "- **conditionally stable**: the scheme is stable for a particular choice of parameters (for example, $\\Delta t$ is less than some threshold)\n",
    "- **unconditionally stable**: the scheme is always stable\n",
    "\n",
    "Schemes may be stable for some problem/system and not for another, and vice versa.\n",
    "\n",
    "Stability is related to robustness of a method, which is generally a tradeoff between complexity and computational cost. The choice of method and solution strategy depends on what you want, and how long you can wait for it. In general, we almost always want to use the largest $\\Delta t$ allowable. Instead of decreasing the stepsize to avoid stability issues we can also use uncodiontionally stable methods. An example for this is the Backward Euler method which is an implicit Method. In contrast to the Forward Euler method (explicit method), the Backward Euler method is unconditionally stable, but it is also first-order accurate (like the Forward Euler method - you will see higher order methods further down).\n",
    "\n",
    "In the next lecture we will have a more in depth discussion of stability and stiffness. The detailed derivation of higher order methods will also be covered in the next lecture. For now let's look at the backward Euler method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Euler method\n",
    "\n",
    "The Backward Euler method is very similar to the Forward Euler method, except in one way: it uses the slope at the *next* time step: \n",
    "$$\n",
    "    \\left(\\frac{dx}{dt}\\right)_{i+1} \\approx \\frac{x_{i+1} - x_i}{\\Delta t}\n",
    "$$\n",
    "Then, the resulting recursion formula is\n",
    "$$\n",
    "x_{i+1} = x_i + \\Delta t \\left(\\frac{dx}{dt}\\right)_{i+1}, \\text{or } \\\\\n",
    "x_{i+1} = x_i + \\Delta t \\, f(t_{i+1}, x_{i+1})\n",
    "$$\n",
    "where $f(t,x) = dx/dt$.\n",
    "\n",
    "Notice that this recursion formula cannot be directly solved, because $x_{i+1}$ shows up on both sides. This is an **implicit** method, where all the other methods we will cover (Forward Euler, Heun's, and 4th-order Runge-Kutta) are **explicit**. Implicit methods require more work to actually implement and are often more computationally expensive, but they are more stable and can be used with larger time steps.\n",
    "\n",
    "### Backward Euler example\n",
    "For example, let's again consider the relatively simple 1st-order ODE from above\n",
    "$$\n",
    "\\frac{dy}{dt} = f(t,y) = -3 y\n",
    "$$\n",
    "To actually solve this problem with the Backward Euler method, we need to incorporate the derivative function $f(x,y)$ into the recursion formula and solve for $y_{i+1}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "y_{i+1} &= y_i + \\Delta t \\, f(t_{i+1}, y_{i+1}) \\\\\n",
    "y_{i+1} &= y_i + \\Delta t \\, [-3 y_{i+1}] \\\\\n",
    "y_{i+1} (1 + 3 \\Delta t) &= y_i \\\\\n",
    "y_{i+1} &= \\frac{y_i}{1 + 3 \\Delta t}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now we have a useable recursion formula that we can use to solve this problem. Let's use the initial condition $y(0) = 1$. Let's try solving this with the Forward Euler method, integrating over $0 \\leq t \\leq 10$, for a range of time-step size values: $\\Delta t = 0.1, 0.25, 0.5, 0.75$. \n",
    "\n",
    "### Task : Implement the Backward Euler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dydt to integrate\n",
    "f(t, y) = -3 * y\n",
    "\n",
    "# we'll create a simple function to do backward Euler\n",
    "function backward_euler(t_end, y0, dt)\n",
    "    # Simple function to perform backwar Euler iteration for dy/dt = f(t, y) = -3y\n",
    "    # y_{i+1} &= \\frac{y_i}{1 + 3 \\Delta t}\n",
    "    time = 0:dt:t_end\n",
    "    y = zeros(length(time))\n",
    "    y[1] = y0\n",
    "    for idx in 1:length(time)-1\n",
    "        t = time[idx]\n",
    "        y[idx+1] = ... # TODO: fill in the backward Euler iteration for y[idx+1] from the equation above \n",
    "    end\n",
    "    return time, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial condition\n",
    "y0 = 1\n",
    "t_end = 20\n",
    "\n",
    "dt = 0.1\n",
    "time, y = backward_euler(t_end, y0, dt)\n",
    "p1 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.25\n",
    "time, y = backward_euler(t_end, y0, dt)\n",
    "p2 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.5\n",
    "time, y = backward_euler(t_end, y0, dt)\n",
    "p3 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "dt = 0.75\n",
    "time, y = backward_euler(t_end, y0, dt)\n",
    "p4 = plot(time, y, grid=true, title=\"dt = $dt\")\n",
    "\n",
    "plot(p1, p2, p3, p4, layout=(2, 2), legend=false)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher Order Methods\n",
    "\n",
    "The Forward Euler method is a first-order method, meaning that the global error is on the order of the step size to the first power: error $\\sim \\mathcal{O}(\\Delta t)$. We can do better than this and obtain higher-order methods. \n",
    "\n",
    "**Note** The detailed derivation of higher-order methods will be covered in the next lecture. Here, we will just take a look into how to implement them.\n",
    "\n",
    "Let's do another example:\n",
    "\\begin{equation}\n",
    "y^{\\prime} = 8 e^{-t}(1+t) - 2y\n",
    "\\end{equation}\n",
    "with the initial condition $y(0) = 1$, and the domain $0 \\leq t \\leq 7$. This is a linear 1st-order ODE that we can find the analytical solution for comparison:\n",
    "\\begin{equation}\n",
    "y(t) = e^{-2t} (8 t e^t + 1)\n",
    "\\end{equation}\n",
    "\n",
    "To solve, we'll create an function for the derivative and then incorporate that into our Forward Euler code. We'll start with $\\Delta t = 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the derivative function \n",
    "function dydt(t, y)\n",
    "    return 8 * exp(-t) * (1 + t) - 2 * y\n",
    "end\n",
    "\n",
    "# Define the exact solution\n",
    "function exact_solution(t)\n",
    "    return exp(-2 * t) * (8 * t * exp(t) + 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.2\n",
    "t_end = 7\n",
    "t_vals = 0:dt:7\n",
    "y_vals = zeros(length(t_vals))\n",
    "\n",
    "# initial condition\n",
    "y0 = 1\n",
    "\n",
    "# forward Euler loop\n",
    "t_vals, y_vals = forward_euler(t_end, y0, dt, dydt)\n",
    "\n",
    "# Calculate the maximum error\n",
    "y_exact = exact_solution.(t_vals)\n",
    "\n",
    "plot(t_vals, y_exact, label=\"Exact solution\")\n",
    "plot!(t_vals, y_vals, marker=:circle, label=\"Forward Euler solution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heun's method\n",
    "\n",
    "Heun's method is a **predictor-corrector** method; these work by *predicting* a solution at some intermediate location and then using that information to get a better overall answer at the next location (*correcting*). Heun's uses the Forward Euler method to predict the solution at $x_{i+1}$, then uses the average of the slopes at $y_i$ and the predicted $y_{i+1}$ to get a better overall answer for $y_{i+1}$.\n",
    "\n",
    "\\begin{align}\n",
    "\\text{predictor: } y_{i+1}^p &= y_i + \\Delta x f(x_i, y_i) \\\\\n",
    "\\text{corrector: } y_{i+1} &= y_i + \\frac{\\Delta x}{2} \\left( f(x_i, y_i) + f(x_{i+1}, y_{i+1}^p) \\right)\n",
    "\\end{align}\n",
    "\n",
    "Heun's method is second-order accurate, meaning the global error is $\\mathcal{O}(\\Delta x^2)$.\n",
    "\n",
    "Let's see this method in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.2\n",
    "t_vals = 0:dt:7\n",
    "y_vals = zeros(length(t_vals))\n",
    "\n",
    "# initial condition\n",
    "y_vals[1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task : Implement Heun's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.2\n",
    "t_vals = 0:dt:7\n",
    "y_vals = zeros(length(t_vals))\n",
    "\n",
    "# initial condition\n",
    "y_vals[1] = 1\n",
    "\n",
    "# 4th order Runge-Kutta iteration\n",
    "for idx in 1:length(t_vals)-1\n",
    "    t_val = t_vals[idx]\n",
    "    k1 = dydt(t_val, y_vals[idx])\n",
    "    k2 = dydt(t_val + dt / 2, y_vals[idx] + dt * k1 / 2)\n",
    "    k3 = dydt(t_val + dt / 2, y_vals[idx] + dt * k2 / 2)\n",
    "    k4 = dydt(t_val + dt, y_vals[idx] + dt * k3)\n",
    "    y_vals[idx+1] = y_vals[idx] + dt * (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "end\n",
    "\n",
    "# Calculate the maximum error\n",
    "y_exact = exact_solution.(t_vals)\n",
    "\n",
    "println(\"Maximum error: \", abs(maximum(y_exact) - maximum(y_vals)))\n",
    "\n",
    "plot(t_vals, y_exact, label=\"Exact solution\")\n",
    "plot!(t_vals, y_vals, marker=:circle, label=\"Runge-Kutta solution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the error is visibly smaller than for the Forward Euler method–the maximum error is around 0.041, which is very close to $\\Delta x^2 = 0.04$.\n",
    "\n",
    "## Runge-Kutta methods\n",
    "\n",
    "Runge–Kutta methods are a family of methods that use one or more stages; the methods we have discussed so far (Forward Euler and Heun's) actually all fall in this family. There is also a popular fourth-order method: the **fourth-order Runge–Kutta method** (RK4). This uses four stages to get a more accurate solution:\n",
    "\\begin{align}\n",
    "y_{i+1} &= y_i + \\frac{\\Delta x}{6} (k_1 + 2 k_2 + 2 k_3 + k_4) \\\\\n",
    "k_1 &= f(x_i, y_i) \\\\\n",
    "k_2 &= f \\left( x_i + \\frac{\\Delta x}{2}, y_i + \\frac{\\Delta x}{2} k_1 \\right) \\\\\n",
    "k_3 &= f \\left( x_i + \\frac{\\Delta x}{2}, y_i + \\frac{\\Delta x}{2} k_2 \\right) \\\\\n",
    "k_4 &= f \\left( x_i + \\Delta x, y_i + \\Delta x \\, k_3 \\right)\n",
    "\\end{align}\n",
    "\n",
    "This method is explicit and fourth-order accurate: error $\\sim \\mathcal{O}(\\Delta x^4)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.2\n",
    "t_vals = 0:dt:7\n",
    "y_vals = zeros(length(t_vals))\n",
    "\n",
    "# initial condition\n",
    "y_vals[1] = 1\n",
    "\n",
    "# 4th order Runge-Kutta iteration\n",
    "for idx in 1:length(t_vals)-1\n",
    "    t_val = t_vals[idx]\n",
    "    k1 = dydt(t_val, y_vals[idx])\n",
    "    k2 = dydt(t_val + dt / 2, y_vals[idx] + dt * k1 / 2)\n",
    "    k3 = dydt(t_val + dt / 2, y_vals[idx] + dt * k2 / 2)\n",
    "    k4 = dydt(t_val + dt, y_vals[idx] + dt * k3)\n",
    "    y_vals[idx+1] = y_vals[idx] + dt * (k1 + 2 * k2 + 2 * k3 + k4) / 6\n",
    "end\n",
    "\n",
    "\n",
    "println(\"Maximum error: \", abs(maximum(y_exact) - maximum(y_vals)))\n",
    "\n",
    "plot(x_exact, y_exact, label=\"Exact solution\")\n",
    "plot!(t_vals, y_vals, marker=:circle, label=\"Runge-Kutta solution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving ODEs using Julia SciML \n",
    "Julia offers a very powerful ecosystem for solving differential equations which is called SciML. You can think of Julia's SciML as SciPy or MATLAB's standard library but in Julia. It is a collection of packages that are used to solve differential equations. The SciML ecosystem is built on top of the Julia programming language which means it is really fast and easy to use. Also it is fully compatible with machine learning and automatic differentiation (and also supports GPUs - this is a huge plus compared to other packages which often are not compatibel with machine learning libraries). An Introduction to the SciML ecosystem can be found here: https://docs.sciml.ai/Overview/stable/getting_started/getting_started/\n",
    "\n",
    "We will use the OrdinaryDiffEq package to solve the ODEs. An introduction on how to solve differential equations using this package can be found here: https://docs.sciml.ai/DiffEqDocs/stable/getting_started/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"OrdinaryDiffEq\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the SciML package on the ODE we have already solved using our own implemented solvers. We will use the same ODE as before and then call the `ODEProblem` function.\n",
    "This function has the following fields\n",
    "\n",
    "    f: The function in the ODE.\n",
    "    u0: The initial condition.\n",
    "    tspan: The timespan for the problem.\n",
    "    p: The parameters.\n",
    "    kwargs: The keyword arguments passed onto the solves. For example dt for the time step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OrdinaryDiffEq\n",
    "\n",
    "# Define the function, this is the same as dydt above but reframed for the ODEProblem type\n",
    "function simple_f(dy, y, p, t)\n",
    "    dy[1] = 8 * exp(-t) * (1 + t) - 2 * y[1]\n",
    "end\n",
    "\n",
    "# Initial conditions\n",
    "y₀ = [1.0]\n",
    "tspan = (0.0, 7.0)\n",
    "dt = 0.2\n",
    "\n",
    "# Define the problem\n",
    "prob = ODEProblem(simple_f, y₀, tspan, dt=dt)\n",
    "\n",
    "# Solve the problem using the RK4 (Runge-Kutta) algorithm\n",
    "sol = solve(prob, RK4())\n",
    "\n",
    "# Calculate the maximum error\n",
    "t_vals = 0:dt:7\n",
    "exact_vals = exact_solution.(t_vals)\n",
    "numerical_vals = [sol(t)[1] for t in t_vals]\n",
    "max_error = maximum(abs.(exact_vals .- numerical_vals))\n",
    "\n",
    "println(\"Maximum error: \", max_error)\n",
    "\n",
    "# Plot the solution\n",
    "plot(sol, lw=2, label=\"Numerical solution\")\n",
    "plot!(t_vals, exact_vals, lw=4, ls=:dot, label=\"Exact solution\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Harmonic Oscillator Problem\n",
    "\n",
    "We will take a look at a physical example known as the Simple Harmonic Oscillator. This is a classic problem in physics that describes the motion of a mass attached to a spring. The force exerted by the spring is proportional to the displacement of the mass from its equilibrium position, but in the opposite direction. This is often referred to as Hooke's law and can be written as:\n",
    "\n",
    "$$\n",
    "F = -kx\n",
    "$$\n",
    "\n",
    "where $F$ is the force, $k$ is the spring constant, and $x$ is the displacement.\n",
    "\n",
    "By Newton's second law, we know that $F = ma$, where $m$ is the mass and $a$ is the acceleration. Acceleration is the second derivative of the position with respect to time, so we can write this as $a = \\frac{d^2x}{dt^2}$. Substituting this into the equation gives us the differential equation for the simple harmonic oscillator:\n",
    "\n",
    "$$\n",
    "m\\frac{d^2x}{dt^2} = -kx\n",
    "$$\n",
    "\n",
    "or, rearranging:\n",
    "\n",
    "$$\n",
    "\\frac{d^2x}{dt^2} = -\\frac{k}{m}x\n",
    "$$\n",
    "\n",
    "This is a second-order ODE that describes the motion of the mass. In the case of a simple harmonic oscillator, the ratio $\\frac{k}{m}$ is often replaced by $\\omega^2$, where $\\omega$ is the angular frequency of the oscillator.\n",
    "\n",
    "In the following Julia code, we define the problem by implementing a `harmonicoscillator` function, which implements the second-order ODE. We also set the initial conditions for the position `x₀` and velocity `dx₀`, as well as the time span for the simulation.\n",
    "\n",
    "\n",
    "#### Implementing and Solving the Harmonic Oscillator in Julia:\n",
    "\n",
    "The Implementation of the harmonic oscillator problem and how to solve it using the `OrdinaryDiffEq` package is described here: https://docs.sciml.ai/DiffEqDocs/stable/examples/classical_physics/#Second-Order-Linear-ODE \n",
    "\n",
    "Consider a mass-spring system with an angular frequency of $1$ rad/s, initial displacement of $0$ m, and initial velocity of $π/2$ m/s. The ODE becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "ω = 1\n",
    "\n",
    "#Initial Conditions\n",
    "dt = 0.1\n",
    "x₀ = [0.0]\n",
    "dx₀ = [π / 2]\n",
    "tspan = (0.0, 2π)\n",
    "\n",
    "ϕ = atan((dx₀[1] / ω) / x₀[1])\n",
    "A = √(x₀[1]^2 + dx₀[1]^2)\n",
    "\n",
    "#Define the problem\n",
    "function harmonicoscillator(ddu, du, u, ω, t)\n",
    "    ddu .= -ω^2 * u\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pass our `harmonicoscillator` function to the `SecondOrderODEProblem` function toegteher with arguments for the initial conditions and the time span. We will also define a solver. As a starting point we add `Euler()` as a solver. Since this is a discrete solver we also need to define a step size. We will use a step size of 0.5. Note that this stepsize is passen to the  `SecondOrderODEProblem` function not the `solve` function.\n",
    "\n",
    "We will notice that this solver is not very accurate. The error is quite large. This is because the Euler method is a first order method. In general there are different ways to improve the results. One way is to reduce the step size. This will however increase the computational cost. Another way is to use a better (higher order) solver. You can try to use a different solver and see if you can reduce the error. \n",
    "\n",
    "### Task: Add a another solver and try to reduce the error \n",
    "\n",
    "You can find a list of solvers here: https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass to solvers\n",
    "prob = SecondOrderODEProblem(harmonicoscillator, dx₀, x₀, tspan, ω, dt=dt)\n",
    "sol = solve(prob, Euler())\n",
    "\n",
    "#Plot\n",
    "plot(sol, vars=[2, 1], linewidth=2, title=\"Simple Harmonic Oscillator\",\n",
    "    xaxis=\"Time\", yaxis=\"Elongation\", label=[\"x\" \"dx\"])\n",
    "plot!(t -> A * cos(ω * t - ϕ), lw=3, ls=:dash, label=\"Analytical Solution x\")\n",
    "plot!(t -> -A * ω * sin(ω * t - ϕ), lw=3, ls=:dash, label=\"Analytical Solution dx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider a mass-spring system with an angular frequency of 1 rad/s, initial displacement of 2 m, and initial velocity of 0.0 m/s. The ODE becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OrdinaryDiffEq, Plots\n",
    "#Parameters\n",
    "ω = 2\n",
    "\n",
    "#Initial Conditions\n",
    "x₀ = [2.0]\n",
    "dx₀ = [0.0] # [π / 2]\n",
    "tspan = (0.0, 2π)\n",
    "\n",
    "ϕ = atan((dx₀[1] / ω) / x₀[1])\n",
    "A = √(x₀[1]^2 + dx₀[1]^2)\n",
    "\n",
    "#Define the problem\n",
    "function harmonicoscillator_2(ddu, du, u, ω, t)\n",
    "    ddu .= -ω^2 * u\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try your solver on this ODE as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass to solvers\n",
    "prob_2 = SecondOrderODEProblem(harmonicoscillator_2, dx₀, x₀, tspan, ω)\n",
    "sol_2 = solve(prob_2, ...) # Add the solver here\n",
    "\n",
    "#Plot\n",
    "plot(sol_2, vars=[2, 1], linewidth=2, title=\"Simple Harmonic Oscillator\",\n",
    "    xaxis=\"Time\", yaxis=\"Elongation\", label=[\"x\" \"dx\"])\n",
    "plot!(t -> A * cos(ω * t - ϕ), lw=3, ls=:dash, label=\"Analytical Solution x\")\n",
    "plot!(t -> -A * ω * sin(ω * t - ϕ), lw=3, ls=:dash, label=\"Analytical Solution dx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
