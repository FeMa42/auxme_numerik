{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives of a functions using Finite Differences - Differenzenquotient\n",
    "In the lecture, we learned different ways to calculate the derivative of a function:\n",
    "- finite differences\n",
    "    - forward difference\n",
    "    - central difference\n",
    "- automatic differentiation (AD)\n",
    "    - forward mode (future exercise)\n",
    "    - reverse mode (future exercise)\n",
    "\n",
    "The derivative of a function $f(x)$ can be approximated by the finite differences:\n",
    "$$\n",
    "\\frac{d f}{d x} \\approx \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}\n",
    "$$\n",
    "This is called the forward difference. We can also use the central difference:\n",
    "$$\n",
    "\\frac{d f}{d x} \\approx \\frac{f(x + \\Delta x) - f(x - \\Delta x)}{2 \\Delta x}\n",
    "$$\n",
    "\n",
    "In the lecture we already discussed that the step size $\\Delta x$ has a big influence on the error of the approximation. We want to investigate this influence and visualize the error for different step sizes $\\Delta x$. What is the smallest number we can use for $\\Delta x$? What happens if we use such a small number? What happens if we use a larger number? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.generate(\"finitediff\")\n",
    "Pkg.activate(\"finitediff\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"FiniteDifferences\")\n",
    "Pkg.add(\"Printf\")\n",
    "Pkg.add(\"LinearAlgebra\")\n",
    "Pkg.add(\"Revise\")\n",
    "\n",
    "Pkg.add(\"RigidBodyDynamics\")\n",
    "Pkg.add(\"MeshCatMechanisms\")\n",
    "Pkg.add(\"MeshCat\")\n",
    "Pkg.add(\"StaticArrays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.activate(\"finitediff\")\n",
    "using FiniteDifferences\n",
    "using Printf\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first let's take a look at the forward and central finite difference methods. We let's start by defining a function we want to differentiate together with the differentiation so that we can estimate the error we are making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function and its derivative\n",
    "function f(x)\n",
    "    x^2 + sin(x)\n",
    "end\n",
    "\n",
    "function df(x)\n",
    "    2 * x + cos(x)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the point `x` at which we want to evaluate the derivative. An compare the forward finite difference method with the central finite difference method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point where we want to approximate the derivative\n",
    "x = 2.0\n",
    "\n",
    "# testing the finite difference methods for the function f(x) = x^2+sin(x)\n",
    "central_fdm(2, 1)(f, x) # 2 is the number of points and 1 is the order of the derivative\n",
    "forward_fdm(2, 1)(f, x)\n",
    "df(x)\n",
    "error_cforward = abs(forward_fdm(2, 1)(f, 2) - df(x))\n",
    "error_central = abs(central_fdm(2, 1)(f, 2) - df(x))\n",
    "@printf(\"Error for forward difference: %.14f\\n\", error_cforward)\n",
    "@printf(\"Error for central difference: %.14f\\n\", error_central)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Step Sizes\n",
    "\n",
    "Write a function which takes the function $f(x)$, a value for $x$, and a vector of step sizes $\\Delta x$ and returns the forward and central differences of $f(x)$ at $x$ for the different step sizes $\\Delta x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function FiniteDifferenceMethod(x::Real, our_eps::Vector, f::Function)\n",
    "# hint: use the point operator\n",
    "    forward = ... \n",
    "    central = ...\n",
    "    forward, central\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our implementation for different eps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps1 = 1e-2\n",
    "eps2 = 1e-10\n",
    "# FiniteDifferenceMethod(x, eps_range, f)\n",
    "forward1, central1 = FiniteDifferenceMethod(x, [eps1], f)\n",
    "forward2, central2 = FiniteDifferenceMethod(x, [eps2], f)\n",
    "\n",
    "@printf(\"With eps = %.2e:\\n\", eps1)\n",
    "@printf(\"Forward difference approximation: %.6f\\n\", forward1[1])\n",
    "@printf(\"Central difference approximation: %.6f\\n\", central1[1])\n",
    "@printf(\"Error forward difference approximation: %.10f\\n\", abs(forward1[1] - df(2)))\n",
    "@printf(\"Error central difference approximation: %.10f\\n\", abs(central1[1] - df(2)))\n",
    "@printf(\"\\nWith eps = %.2e:\\n\", eps2)\n",
    "@printf(\"Forward difference approximation: %.6f\\n\", forward2[1])\n",
    "@printf(\"Central difference approximation: %.6f\\n\", central2[1])\n",
    "@printf(\"Error forward difference approximation: %.10f\\n\", abs(forward2[1] - df(2)))\n",
    "@printf(\"Error central difference approximation: %.10f\\n\", abs(central2[1] - df(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Step Sizes based on the machine precision $\\epsilon$\n",
    "\n",
    "First lets check our machine precision $\\epsilon$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = eps(Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this number tell us? Since floating point numbers are scaled there is a limit to the precision of the numbers we want to represent and perform operations with. This is however relative to the size of the number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show eps(1.0)\n",
    "@show eps(0.1)\n",
    "@show eps(0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the lecture this can be a problem if we substract numbers that are close to each other. Let's check this again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ = 1e-10rand()\n",
    "@show ϵ \n",
    "@show (1+ϵ)\n",
    "@show ϵ2 = (1+ϵ) - 1\n",
    "@show (ϵ - ϵ2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding 1 to the small random number we lose the information of the last digits of the small number. When we substract 1 again we don't get the same number back. Hence, we have a loss of precision.\n",
    "\n",
    "Ok, so now we want to see how this influence our finite differences approach. We learned that $\\sqrt{\\epsilon}$ is a good choice for $\\Delta x$. In general we cannot expect a lower error than approximately $\\sqrt{\\epsilon} \\approx 10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show sqrt(eps(Float64));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use $\\Delta x = 2.3*10^{-16}$ as the smallest number. For the largest number we use $\\Delta x = 0.1$. Let's plot the error for different step sizes $\\Delta x$.\n",
    "\n",
    "Plot the error of the the forward and central difference for the function $f(x) = x^2+sin(x)$ and for different step sizes $\\Delta x$ from $0.1$ to $10^{-16}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plots\n",
    "using LinearAlgebra\n",
    "f(x) = x^2+sin(x)\n",
    "df(x) = 2*x+cos(x) # analytical derivative of f to estimate the error\n",
    "\n",
    "eps_length = 16\n",
    "eps_range = 10 .^ -range(1, stop=16, length=eps_length)\n",
    "eps_range[eps_length] = 2.3*10^-16 # set the last element to 2.3e-16\n",
    "x = 1.0\n",
    "real_dfx = df(x)\n",
    "df_forw_eps, df_cent_eps = FiniteDifferenceMethod(x, eps_range, f)\n",
    "\n",
    "# TODO: estimate the absolute error using FiniteDifferenceMethod; don't forget to use the point operator\n",
    "error_forward = ...  \n",
    "error_central = ...\n",
    "\n",
    "p1 = Plots.scatter(eps_range, error_forward, label=\"err(eps)\" , title=\"forward\", xlabel=\"log eps\", ylabel=\"log error\", xscale=:log10, yscale=:log10)\n",
    "p2= Plots.scatter(eps_range, error_central, label=\"err(eps)\" , title=\"central\", xlabel=\"log eps\", ylabel=\"log error\", xscale=:log10, yscale=:log10)\n",
    "Plots.plot(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = 10 .^ -range(4, stop=6, length=1000)\n",
    "df_fd_eps, df_cd_eps = FiniteDifferenceMethod(x, eps_range, f)\n",
    "\n",
    "# TODO: estimate the absolute error\n",
    "error_central = ...\n",
    "error_forward = ...\n",
    "\n",
    "p3 = Plots.scatter(eps_range, error_central, label=\"err(eps)\" , title=\"central\", xlabel=\"eps\", ylabel=\"error\", xscale=:log10, yscale=:log10)\n",
    "p4 = Plots.scatter(eps_range, error_forward, label=\"err(eps)\" , title=\"forward\", xlabel=\"eps\", ylabel=\"error\", xscale=:log10, yscale=:log10)\n",
    "Plots.plot(p3, p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives of a function with multiple variables with finite differences\n",
    "We have learned that the partial derivative of a function $f(x,y)$ with respect to $x$ is estimated by keeping $y$ constant and vice versa. We can use this approach to estimate the partial derivative using finite differences. Since the gradient of a function $f(x,y)$ is defined as:\n",
    "$$\n",
    "\\nabla f = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "We can estimate the gradient with the partial derivative for each variable seperately.\n",
    "\n",
    "Let's try this for the function $f(x, y) = x^2 + x*y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x, y) = x^2 + x * y\n",
    "a, b = 1.0, 1.0 # We want to estimate the partial derivatives of f at (a,b)\n",
    "\n",
    "f_x(x) = f(x, b)\n",
    "f_y(y) = f(a, y)\n",
    "\n",
    "real_df_dx = 2 * a + b\n",
    "real_df_dy = a\n",
    "\n",
    "df_dx_f_c = FiniteDifferenceMethod(a, [10^-8], f_x)\n",
    "df_dy_f_c = FiniteDifferenceMethod(b, [10^-8], f_y)\n",
    "df_dx = df_dx_f_c[2][1]\n",
    "df_dy = df_dy_f_c[2][1]\n",
    "@show grad_f = [df_dx, df_dy]\n",
    "@show real_grad_f = [real_df_dx, real_df_dy];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have another equation $g(x,y) = x^2 + y^2$ we can calculate the total derivative of the system of equations $f(x,y)$ and $g(x,y)$ with respect to $x$ and $y$ which is the Jacobian matrix:\n",
    "$$\n",
    "\\mathbf{J} = \\begin{bmatrix}\n",
    "\\nabla f \\\\\n",
    " \\nabla g\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y} \\\\\n",
    "\\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y}\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g(x, y) = x^2 + y^2\n",
    "\n",
    "g_x(x) = g(x, b)\n",
    "g_y(y) = g(a, y)\n",
    "\n",
    "real_dg_dx = 2 * a\n",
    "real_dg_dy = 2 * b\n",
    "\n",
    "dg_dx_f_c = FiniteDifferenceMethod(a, [10^-8], g_x)\n",
    "dg_dy_f_c = FiniteDifferenceMethod(b, [10^-8], g_y)\n",
    "dg_dx = dg_dx_f_c[2][1]\n",
    "dg_dy = dg_dy_f_c[2][1]\n",
    "@show grad_g = [dg_dx, dg_dy]\n",
    "@show real_grad_g = [real_dg_dx, real_dg_dy]\n",
    "@show jacobian_f = [df_dx df_dy; dg_dx dg_dy];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used an inefficient way to calculate the Jacobian. We needed to calculate the partial derivative of each function with respect to each variable. There are more efficient ways to calculate the Jacobian matrix like using colored Jacobians or automatic differentiation (next section).\n",
    "\n",
    "In practice you can use FiniteDifferences.jl to calculate the Jacobian matrix using finite differences. This package can be installed with `Pkg.add(\"FiniteDifferences\")`. \n",
    "Let's try this out for the function \n",
    "$$\n",
    "\\mathbf{f(x)} =  \\begin{bmatrix}\n",
    "x_1^2 + x_1*x_2 \\\\\n",
    "x_1^2 + x_2^2\n",
    "\\end{bmatrix} \n",
    "$$. \n",
    "We can use the function `jacobian` from the package FiniteDifferences.jl to calculate the Jacobian matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FiniteDifferences\n",
    "f(x) = [x[1]^2+x[1]*x[2]; \n",
    "        x[1]^2+x[2]^2]\n",
    "x = [1.0, 1.0]\n",
    "\n",
    "FiniteDifferences.jacobian(FiniteDifferences.central_fdm(2, 1), f, x)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the central difference approximation is of order O(eps^2). It increases quadratically with eps and is smaller than the forward difference approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation the end effector velocity based on the joint velocities\n",
    "\n",
    "We can measure the joint velocities of our Openmanipulator. However, we are interested in the speed of the end effector. We have seen in the lecture that we can calculate the end effector velocity based on the joint velocities using the Jacobian matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Jacobian matrix of the Openmanipulator-X kinematics\n",
    "To estimate the velocity of the end effector we need to know the forward kinematics of the Openmanipulator-X and estimate the derivative of the forward kinematics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../OpenManipulatorLib/OpenManipulatorKinematics.jl\")\n",
    "using .OpenManipulatorKinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the jacobian matrix of the forward kinematics for our robot arm using finite differences. We can use the function `FiniteDifferences.jacobian` to calculate the Jacobian matrix of the forward kinematics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FiniteDifferences\n",
    "\n",
    "function openmanipulator_jacobian(q)\n",
    "    # Define a function that returns the position of the end effector\n",
    "    f(q) = OpenManipulatorKinematics.complete_forward_kinematics(q)[1]\n",
    "    \n",
    "    J = ... # use FiniteDifferences.jacobian to compute the Jacobian of f at q as can be seen done before\n",
    "\n",
    "    return J\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test the methods. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [0.1, 0.0, 0.0, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time openmanipulator_jacobian(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the end effector velocity using the Jacobian matrix\n",
    "\n",
    "In the lecture you learned that based on the total derivative we can derive the rule for differentiating our system of equations $f_1(x,y)$ and $f_2(x,y)$ with respect to the variable $t$ when $x$ and $y$ are functions of $t$:\n",
    "$$\n",
    "\\frac{d}{dt} \\begin{bmatrix}\n",
    "f_1(x,y) \\\\\n",
    "f_2(x,y)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x} & \\frac{\\partial f_1}{\\partial y} \\\\\n",
    "\\frac{\\partial f_2}{\\partial x} & \\frac{\\partial f_2}{\\partial y}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\frac{\\partial x}{\\partial t} \\\\\n",
    "\\frac{\\partial y}{\\partial t}\n",
    "\\end{bmatrix}\n",
    "= \\mathbf{J} \\begin{bmatrix}\n",
    "\\frac{\\partial x}{\\partial t} \\\\\n",
    "\\frac{\\partial y}{\\partial t}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Based on this rule we can estimate the end effector velocity using the Jacobian matrix. We can use the following estimation:\n",
    "$$\n",
    "v = \\mathbf{J}(q) * \\mathbf{q}_v = \\mathbf{J}(q) * \\begin{bmatrix}\n",
    "\\frac{\\partial q_1}{\\partial t} \\\\\n",
    "\\frac{\\partial  q_2}{\\partial t} \\\\\n",
    "\\frac{\\partial  q_3}{\\partial t} \\\\\n",
    "\\frac{\\partial  q_4}{\\partial t} \\\\\n",
    "\\end{bmatrix} \n",
    "\\approx J(q) * \\begin{bmatrix}\n",
    "\\Delta q_1 \\\\\n",
    "\\Delta q_2 \\\\\n",
    "\\Delta q_3 \\\\\n",
    "\\Delta q_4 \\\\\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "where $v$ is the end effector velocity, $\\mathbf{J}(q)$ is the Jacobian matrix evaluated at the current joint angles $q$, and $\\mathbf{q}_v$ is the joint velocity vector, which we can estimate with the joint approximate velocities $\\Delta q_1$, $\\Delta q_2$, $\\Delta q_3$, and $\\Delta q_4$.\n",
    "\n",
    "Implement the `endeffector_velocity` function that uses the Jacobian matrix to calculate the end effector velocity. The function should take the joint angles `q` and joint velocity vector `q_v`, and returns the end effector velocity `v` calculated using the Jacobian matrix. Use the `openmanipulator_jacobian` function you implemented to calculate the Jacobian matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function endeffector_velocity(q, q_v)\n",
    "    # TODO\n",
    "    # Calculate the Jacobian matrix at the current joint angles\n",
    "    ##J = ...\n",
    "    # Calculate the end effector velocity using the Jacobian matrix\n",
    "    ##v = ...\n",
    "\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function with the following joint angles and joint velocities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_v = [0.0, 0.0, 0.0, 0.0]\n",
    "v = endeffector_velocity(q, q_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_v = [0.0, 0.5, 0.0, 0.0]\n",
    "v = endeffector_velocity(q, q_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Openmanipulator-X model and calculate the Jacobian matrix using the `openmanipulator_jacobian` function. We can use the `endeffector_velocity` function to calculate the end effector velocity based on the joint velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RigidBodyDynamics\n",
    "using MeshCatMechanisms\n",
    "using MeshCat\n",
    "using LinearAlgebra\n",
    "using StaticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcdir = \"../open_manipulator_description/urdf/\"\n",
    "urdf = joinpath(srcdir, \"open_manipulator.urdf\")\n",
    "mechanism = parse_urdf(urdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvis = MechanismVisualizer(mechanism, URDFVisuals(urdf));\n",
    "render(mvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time = 3.0\n",
    "ts, qs, vs = simulate(mvis.state, final_time);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = mvis.state\n",
    "set_configuration!(mvis, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "zero_velocity!(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = mvis.state\n",
    "@show joint_state = mvis.state.q\n",
    "@show velocity = mvis.state.v;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the controller method we introduced in exercise 3 (the introduction of the Openmanipulator-X). \n",
    "\n",
    "We can use the `endeffector_velocity` function to calculate the end effector velocity based on the joint velocities. We can use this information to extend the control method of the robot arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om_joints = joints(mechanism)\n",
    "function joint_position_control(q_state, v_state, q_desired)\n",
    "    kp = 2.0\n",
    "    v_damping = 0.5\n",
    "    max_torque = 1.0\n",
    "\n",
    "    torque = kp * (q_desired - q_state) - v_damping * v_state\n",
    "    torque = clamp.(torque, -max_torque, max_torque)\n",
    "\n",
    "    return torque\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simple_joint_control!(torques::AbstractVector, t, state::MechanismState)\n",
    "    joint_number = 1\n",
    "    position = 0.5\n",
    "\n",
    "    for j_iter in 1:6\n",
    "        if j_iter != joint_number\n",
    "            state.v[j_iter] = 0.0\n",
    "        end\n",
    "    end\n",
    "    for joint in om_joints\n",
    "        torques[velocity_range(state, joint)] .= 0.0\n",
    "    end\n",
    "    torques[velocity_range(state, om_joints[joint_number])] .= joint_position_control(state.q[joint_number], state.v[joint_number], position)\n",
    "    v = endeffector_velocity(state.q[1:4], q_v[1:4])\n",
    "    println(\"End effector velocity: \", v)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_time = 2.0\n",
    "ts, qs, vs = simulate(mvis.state, final_time, simple_joint_control!; Δt=1e-2);\n",
    "MeshCatMechanisms.animate(mvis, ts, qs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
