{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares \n",
    "\n",
    "## Introduction with a linear function\n",
    "In the lecture we started the discussion of the least squares method using the example of a linear function $f(x) = ax + b$ and a set of data points $(x_i, y_i)$, $i=1,\\ldots,n$. We defined the error function as\n",
    "$$\n",
    "L(a,b) = \\sum_{i=1}^n (y_i - y(x_i))^2 = \\sum_{i=1}^n r_i = r^T r=\\|r\\|^2,\n",
    "$$\n",
    "where $y(x_i) = ax_i + b$ is the linear function and $r_i$ is the residual for the $i$-th data point. The least squares method then consists in finding the values of $a$ and $b$ that minimize the error function $L(a,b)$:\n",
    "$$\n",
    "\\min_{a,b} L(a,b).\n",
    "$$\n",
    "In general this is an optimization problem that can be solved using the methods discussed in the lecture. However, in the case of a linear function $f(x) = ax + b$ we learned that the solution can be found in closed form. We can rewrite the error $r$ as\n",
    "$$\n",
    "r = \\begin{pmatrix}\n",
    "r_1 \\\\\n",
    "r_2 \\\\\n",
    "\\vdots \\\\\n",
    "r_n\n",
    "\\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "1  x_1 \\\\\n",
    "1  x_2 \\\\\n",
    "\\vdots \\vdots \\\\\n",
    "1  x_n\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "a \\\\\n",
    "b\n",
    "\\end{pmatrix} -\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix} = A p - y,\n",
    "$$\n",
    "where $p = (a,b)^T$ is the vector of parameters. This is similar to the linear system $Ax = b$ that we discussed in the lasst exercise. However, this time our system of equations is overdetermined, i.e. we have more equations than unknowns. In this case we cannot expect to find a solution $p$ such that $Ap = y$ (i.e. $r=0$). Instead we have to find a solution $p$ such that $Ap \\approx y$, i.e. $r \\approx 0$. The least squares solution is defined as the solution that minimizes the error $\\|r\\|^2$. We can find this solution by solving the normal equations\n",
    "$$\n",
    "A^T A p^* = A^T y.\n",
    "$$\n",
    "In the case of a linear function $f(x) = ax + b$ we can solve these equations in closed form and obtain the solution\n",
    "$$\n",
    "p^* = (A^T A)^{-1} A^T y.\n",
    "$$\n",
    "Remember that $(A^T A)^{-1} A^T$ is called the Moore-Penrose pseudoinverse of $A$ and is denoted by $A^+$. We can now compute the least squares solution $p^*$ for a given set of data points $(x_i, y_i)$, $i=1,\\ldots,n$ if $A$ is not rank deficient. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Least Squares Tasks\n",
    "\n",
    "### Setup\n",
    "\n",
    "First, we'll need to generate a set of data points that roughly follow a linear trend but with some noise added. We'll use the function $f(x) = 2x + 3$ to generate the $y_i$ values. We'll then add some Gaussian noise to the $y_i$ values to simulate real-world measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.generate(\"learningF\")\n",
    "Pkg.activate(\"learningF\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"Statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x values\n",
    "x = LinRange(-10, 10, 100)\n",
    "\n",
    "# Generate y values with added noise\n",
    "y = 2 .* x .+ 3 + randn(length(x))\n",
    "\n",
    "# Plot the data points\n",
    "scatter(x, y, label=\"Data Points\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Matrix Formation\n",
    "\n",
    "The next step is to form the matrix $A$. \n",
    "\n",
    "1. Construct the matrix $A$. Remember, the first column should be all ones (for the constant term in the linear function) and the second column should be the $x_i$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Solving the Normal Equations\n",
    "\n",
    "Now, we are ready to solve the normal equations to get the least squares solution.\n",
    "\n",
    "1. Compute the matrix $A^T A$ and the vector $A^T y$ in a seperate cell and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix $A^T A$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the vector $A^T y$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Solve the system of equations $A^T A p = A^T y$ to find $p$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the linear system $A^T A p = A^T y$\n",
    "p = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Verification\n",
    "\n",
    "Finally, verify the solution you obtained. \n",
    "\n",
    "1. Compute the residuals $r_i$ and the total  mean squared error.\n",
    "\n",
    "2. Plot the original data points, the true line $f(x)$, and the line corresponding to your solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the residuals $r_i$ and the total mean squared error\n",
    "residuals = ...\n",
    "error = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data points, the true line $f(x)$, and the line corresponding to your solution.\n",
    "plot!(x, p[1] .+ p[2] .* x, label=\"Least Squares Solution\")\n",
    "plot!(x, 2 .* x .+ 3, label=\"True Line\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Using the Julia built-in function\n",
    "You can use also the build in function `\\` to solve linear equations in Julia since it uses the least squares method if the system is overdetermined. \n",
    "\n",
    "1. Build a linear equation of type $Ax=b$ and solve it with the `\\` function. Compare the result with the solution you obtained erlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the linear equation using the build in function\n",
    "A = ...\n",
    "b = ...\n",
    "p = A \\ b\n",
    "\n",
    "# Compute the residuals $r_i$ and the total mean squared error\n",
    "residuals = ...\n",
    "error = ...\n",
    "println(\"Error: \", error)\n",
    "\n",
    "# Plot the original data points, the true line $f(x)$, and the line corresponding to your solution.\n",
    "plot!(x, p[1] .+ p[2] .* x, label=\"Least Squares Solution\")\n",
    "plot!(x, 2 .* x .+ 3, label=\"True Line\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Implement a function that computes the least squares solution\n",
    "Now we want to implement a function that computes the least squares solution for a given set of data points $(x_i, y_i)$, $i=1,\\ldots,n$.\n",
    "\n",
    "1. Implement a function `least_squares` that takes as input the vectors $x$ and $y$ and returns the least squares solution $p^*$ together with the matrix $A$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function least_squares(x, y)\n",
    "    \n",
    "    p, A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, A = least_squares(x, y)\n",
    "residuals = ...\n",
    "error = ...\n",
    "println(\"Error: \", error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Least Squares using real world data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measured the current $I$ of the first joint of our Openmanipulator robot for different goal currents $I_g$ and obtained the following data points seen in the image below: \n",
    "\n",
    "<img src=\"./omp_currents.png\">\n",
    "\n",
    "We want to find a linear function $I = f(I_g)$ that describes the relationship between the goal current $I_g$ and the actual current $I$. We want to know how accuarate we can predict the actual current $I$ for a given goal current $I_g$. Fist let's load the data points into Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkg.add(\"CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "\n",
    "csv = CSV.File(joinpath(@__DIR__, \"omp_currents.csv\"))      # load and parse csv\n",
    "\n",
    "x_train = csv.columns[5].column                      # mask column 5 (Goal Current)\n",
    "y_train = csv.columns[4].column                      # mask column 4 (Present Current)\n",
    "\n",
    "mean = Statistics.mean(x_train)           # calculate the mean\n",
    "std = Statistics.std(x_train)             # calculate the variance\n",
    "\n",
    "function dataPreProcess(x, y)\n",
    "    x = Float64.(x)\n",
    "    y = Float64.(y)\n",
    "    # make the data zero mean and unit variance\n",
    "    ...\n",
    "    x, y\n",
    "end\n",
    "\n",
    "\n",
    "function dataPostProcess(x, y)\n",
    "    # data post procseeing (make it human frindly again)\n",
    "    ... \n",
    "    x, y\n",
    "end\n",
    "\n",
    "# data pre processing\n",
    "x_train, y_train = dataPreProcess(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the goal current vs the present current\n",
    "plot(x_train, label=\"Goal Current\")\n",
    "plot!(y_train, label=\"Present Current\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Compute the parameters of the linear function\n",
    "Now we want to compute the parameters $p_1$ and $p_2$ of the linear function $I = f(I_g) = p_1*I_g + p_2$ that best fits the data points.\n",
    "\n",
    "1. Compute the parameters $a$ and $b$ of the linear function $I = f(I_g) =p_1*I_g + p_2$ that best fits the data points using the least squares method you implemented earlier.\n",
    "\n",
    "2. Estimate the mean squared error of the linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data points and the line corresponding to your solution\n",
    "scatter(x_train, y_train, xlabel=\"Goal Current\", ylabel=\"Present Current\", label=\"Training Data\", legend=:topleft)\n",
    "# plot the least squares solution\n",
    "plot!(x_train, p[1] .+ p[2] .* x_train, label=\"Least Squares Solution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving underdetermined systems using the pseudoinverse\n",
    "If we have a linear system $Ax = b$ with more unknowns than equations, i.e. $A$ is rank deficient, then we cannot use the known tools to find a solution $x$ such that $Ax = b$. We can however define: \n",
    "$$\n",
    "B = A^T\n",
    "$$\n",
    "and use the pseudoinverse of $B^+$ \n",
    "$$\n",
    "B^+ = (B^T B)^{-1} B^T\n",
    "$$\n",
    "with \n",
    "$$\n",
    "(B^+)^T = A^T (A A^T)^{-1}\n",
    "$$\n",
    "Hence, if we use the pseudoinverse of the system we find the solution with minimal norm, i.e. the solution that minimizes $\\|x\\|$. In this exercise we will use the pseudoinverse to find the least squares solution of an underdetermined system of equations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We first need to create an underdetermined system of equations. Let's make this system a little simpler for ease of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 2x3 matrix $A$ with random values.\n",
    "A = rand(2, 3)\n",
    "\n",
    "# 2-dimensional vector $b$ also with random values.\n",
    "b = rand(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Compute the Pseudoinverse\n",
    "\n",
    "Now we will compute the pseudoinverse $B^+$ of the transposed matrix $B = A^T$.\n",
    "\n",
    "1. Compute the matrix $B$ by transposing $A$.\n",
    "\n",
    "2. Compute the pseudoinverse $B^+$ using the formula provided. Note that this might involve computing a matrix inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix $B$ by transposing $A$.\n",
    "\n",
    "# Compute the pseudoinverse $B^+$ using B^+ = (B^T B)^{-1} B^T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Solve the Underdetermined System\n",
    "\n",
    "With the pseudoinverse $B^+$, we can now solve for $x$.\n",
    "\n",
    "1. Compute the solution $x = (B^+)^T b$.\n",
    "\n",
    "2. Print the solution $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the solution $x = (B^+ b$.\n",
    "\n",
    "# Print the solution $x$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Verification\n",
    "\n",
    "Finally, we should verify the solution we obtained.\n",
    "\n",
    "1. Compute the vector $Ax$ and compare it with $b$. Given that we have an underdetermined system, they do not have to be the same.\n",
    "\n",
    "2. Compute the norm of $x$ \n",
    "\n",
    "3. Compare your solution with the one obtained using the function `\\`. Also compare the norm of the solution obtained with `\\` with the norm of the solution obtained with the pseudoinverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the vector $Ax$ and compare it with $b$. Given that we have an underdetermined system, they do not have to be the same. \n",
    "\n",
    "\n",
    "# Compute the norm of $x$ and discuss why this solution is preferable when we have an underdetermined system.\n",
    "\n",
    "\n",
    "# compare to \\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
