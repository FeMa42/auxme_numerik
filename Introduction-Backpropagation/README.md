# Introduction to Backrpopagation in Julia

An introduction to the backpropagation algorithm in Julia. 

In `Lecture-Intro-Backpropagation-p1.ipynb` we start with defining a Value and building a Computational Graph. We then go backward on this grad and compute the gradients at each step. 

In `Lecture-Intro-Backpropagation-p2.ipynb` we take a look at how we can go backward automatically, define a simple neuron and train it on a simple goal value.


## Credits

It is based on Karpathy's [nn-zero-to-hero](https://github.com/karpathy/nn-zero-to-hero/tree/73c3fcc741f0ec104ca850b1fb0df90e7e8d4cde/lectures/micrograd) and [Microgram.jl](https://github.com/ajloza/Micrograd.jl), which is a port of [micrograd](https://github.com/karpathy/micrograd) to julia.  
